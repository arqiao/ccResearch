# ClawdBot 爆火背后：我们正在重演 AutoGPT 的狂欢吗？
# URL: https://mp.weixin.qq.com/s/j5VaL5p78vBhEHhP4CqBPQ
# 日期: 2026-02-08
# 来源: 微信-蔡荔谈AI
# 分类: 产品认知 / 
# 字数: 2764

一、 引言
2026年1月，一个叫
ClawdBot
的开源项目突然火了。
做的事情其实不新鲜：本地 AI 助手，帮你处理邮件、管理日程、搜索信息。
不一样的是，这次它真的在干活。
这个 AI 不再像个聊天机器人，更像一个员工。它会定期唤醒自己，回顾上下文，思考，然后判断要不要采取行动。
GitHub star
数飙升，社交媒体上到处是演示视频。那种氛围，熟悉得让人心里发慌。
二、 似曾相识
这场景，2023年初见过。
当时叫
AutoGPT
。
GPT-4
刚发布，它的多步推理能力刚好能支撑链式智能体循环。项目本身很简单，就是把大模型的思考过程串联起来。
但它点燃了一个信念：
自主智能体时代近在眼前
。
社交媒体上到处是演示：AI 智能体能自主完成市场调研、写代码、做内容。那段时间，大家觉得未来好像提前到来了。
然后就被现实泼了冷水。
Token 成本飙升，智能体经常陷入无限循环，面对真实世界的复杂场景，上下文窗口根本撑不住。
用户发现自己花在监督智能体上的时间，比让它们干活的时间还多。
没过几个月，大家就默默弃用了。
三、 ClawdBot 的突破
ClawdBot
的突破，源于
Claude Opus 4.5
的推出。
它跨过了一道门槛：让大模型从只会聊天的顾问，变成半可靠的执行者。
Claude Opus 4.5
的工具调用能力和长上下文推理能力都增强了，不仅能链式调用工具，还能从错误中恢复。
这让
ClawdBot
得以与消息应用、日历等真实世界的界面连接起来。
技术上确实有进步。但核心定位其实和当年的 AutoGPT 没什么区别：
展现了一种刚解锁的新能力，但这种能力还没找到稳定的产品形态。
四、 成本
OpenClaw
软件本身免费，但真正烧钱的是大模型的
token
消耗。
有人算了笔账：用 Claude Opus 4.5 处理邮件、日程、轻量调研，每天消耗约 2M tokens，输入成本
天
，
输
出
成
本
4.00/天。
总计约
天
，
或
400-450/月。
这已经超过了大多数人在生产力工具上的总支出。
而且这笔支出不稳定也不透明，因为你无法精确控制 AI 会"思考"多久。
有人尝试用低成本模型替代，但在复杂工作流里，这些模型远没那么可靠。工具调用失败，指令理解不到位，深度推理频频翻车。
资深用户的策略：
把心跳检测这类简单任务交给低价模型，需要推理的复杂工作留给 Opus。
通过极致优化并采用多模型架构，每月成本能降到 $70 左右。
但如果没有这种规划，每月成本通常会落在 $300-750 之间。这时候它就不再是可靠的工具，而是烧钱的玩具。
五、 安全
OpenClaw
刚火起来，安全警报就拉响了。
原因很简单：它让模型直接获得系统级访问权限。
这种设计让用户觉得强大又爽快，但也带来了最大的风险。
提示注入攻击、账户被盗、恶意插件……
核心问题：
LLM 无法可靠地区分"指令"和"data"。
只要把两者混在同一个上下文窗口里，就永远存在被绕过的可能。
这不是 bug，而是当前主流
transformer
范式的架构级问题。
OpenAI 2025 年底承认
：对 browser agent 来说，prompt injection "unlikely to ever be fully solved"
Anthropic 2025 年 11 月
：即使 Claude Opus 4.5 把攻击成功率压到 1% 左右，"仍然不是 solved problem"
OWASP LLM Top 10
：Prompt Injection 连续多年稳居第一
现实的态度：像对待 SQL 注入一样对待它——别幻想根治，要持续管理、持续对抗。
六、 工程上的亮点
尽管有这些问题，
ClawdBot
的架构设计确实值得学习。
它基本把个人 AI 助手这个方向能踩的坑都踩完了，给出了一套工程上真正跑得通、维护得了、扩展得动的方案。
很多做
AI Agent
的公司花几百万请架构师，设计出来的东西都不如它精妙。
受其启发，两个轻量级项目应运而生：
6.1 Nanobot
香港大学数据智能实验室开源的超轻量版本——43 万行代码精简到 4000 多行，只有原版的 1% 左右。
架构清晰，四层分层解耦：
接入层、消息路由层、核心推理层、模型抽象层
。
想学
AI Agent
架构设计的，这个项目拆起来比原版友好太多。
6.2 Nanoclaw
另一位开发者看到
OpenClaw
那个臃肿的代码库直接心态崩了：52+ 模块、8 个配置文件、45+ 依赖。
于是整了个
NanoClaw
，代码量砍到 8 分钟就能看完的程度，Apple 容器中运行，代理在里面跑，搞不了事。
七、 历史的教训
AutoGPT 的失败，不是因为智能体这个概念不对，而是它只展示了潜在能力，却没做出一个稳定、可控、好用的产品。
每当新能力解锁，总会催生一批爆火的产品。
往往是开源项目，主打灵活性，力求吸引最多关注。
但真正能沉淀持久价值的，是那些减少而非增加自由度的产品。
演示翻车的方式有几个：
短时间引导下看似稳定的系统，持续实际使用时却脆弱不堪
让演示显得神奇的无约束能力，很快会变成安全与管控的大麻烦
演示中藏着的经济账，到了生产阶段就会浮出水面
能力突破阈值的速度，远超可靠性、控制机制和成本管控的追赶节奏。
八、 最后
ClawdBot
确实展现了 AI 智能体的潜力，它的架构设计也有很多值得学习的地方。
更重要的是，聪明钱已经在动了。
王慧文在即刻上公开喊话：
做 OpenClaw 相关领域创业的团队，需要融资的联系他；想组局进入这个领域的，也联系他；甚至想加入相关创业公司的人，他也愿意牵线。
当一个经历过千亿级公司从 0 到 1 的人，看到一个赛道愿意再次出手，这本身就是最强的信号。
历史不会重复，但会押韵。
2023 年的
AutoGPT
狂热教会我们一件事：
从能力演示到成熟产品，中间隔着一条巨大的鸿沟。
但这一次，跨过鸿沟的条件可能真的在成熟——模型能力更强了，工程方案更完善了，而且最关键的是，真正懂得把技术变成产品的人，正在入场。
2026 年的
ClawdBot
，也许真的会给出不同的答案。
九、 延伸阅读：
[
Nanobot GitHub
]
https://github.com/HKUDS/nanobot
[
Nanoclaw GitHub
]
https://github.com/gavrielc/nanoclaw
[
OpenClaw 项目
]
https://github.com/OpenClaw-LLM/OpenClaw