# ​OpenClaw 之后，清华系团队给端侧 AI 找了一条「端云协同」的新路
# URL: https://mp.weixin.qq.com/s/4OWq1cwNjDa6Xxi5THeM6Q
# 日期: 2026-02-10
# 来源: 微信-极客公园
# 分类: 安装部署 / 通用部署
# 字数: 3740

用端云协同，让手机智能体更聪明、更可控。
2026 年都到 2 月了，你要是还没听说过 Agentic AI，大概率不只是断网这么简单——更像是手机都丢了。
我自己算是从头看着这波浪潮起来的。OpenClaw（当时还叫 ClawdBot）火出圈那阵子，很多人第一次真正「看懂」了一件事：我们想象中的 AI Agent 时代，关键从来不在它能不能聊得更像人，而在它能不能把事办完。
它能开浏览器、能点按钮、能把一个原本需要你反复切 App 的任务拆成步骤，一路执行到结束。你甚至会在某个瞬间产生错觉：屏幕那头像真的坐着一个很熟练的实习助理。
与此同时，自动化操作这股风，早就吹到手机上了。无论是豆包手机这类软硬件形态，还是各家手机大厂在系统助手上的「行动化」尝试，本质上都在做同一件事——把 AI 从对话框里拽出来，塞进系统和 App 的缝里，让它去完成那些「明明很简单但就是很烦」的操作链路：打车、下单咖啡、生成文档。
然而，单纯的云侧智能或单纯的端侧执行，都有着各自难以逾越的「天花板」。
云侧的 OpenClaw 拥有强大的推理能力，但它看不见你手机当下的屏幕，不知道你此刻的地理位置，更不敢直接操作你本地的微信去发个红包；而市面上常见的纯端侧助手，虽然能调用本地的数据和应用，却往往因为硬件算力限制，在面对高复杂、长流程任务时显得「智商不够用」。
移动端 AI Agent 的胜负手，早就不是「做云还是做端」的选择题，而是如何把两者的优势真正打通。近期，一家清华系团队「万象智维」选择用「小万」切入市场，押注的正是这样一套打通端云的能力体系：
让云端做「大脑」，负责复杂逻辑与规划；让端侧做「手脚」，负责感知与最后一公里执行。
01
不仅是「能动手」，
更是「分工明确」
在 AI Agent 的应用场景中，设备的定位差异始终是制约体验升级的关键。电脑与云服务器是天生的效率工具，凭借 7×24 小时不间断运行的优势，擅长承载复杂计算与长期执行类任务。而手机则是核心生活工具，沉淀着最细碎、最个人化的行为习惯和上下文数据。
传统的思路是：要么把所有数据传上云，但这面临隐私和延迟的挑战；要么在端侧硬跑大模型，但这会烧穿手机的电池和算力。
「万象智维」的解法是
「端侧 GUI + 云侧 CLI」
的技术分工。
在「小万」的产品架构中，手机被定位为
上下文的主要入口与执行终端
。它天然知道你是谁、你现在在什么时间和地点、你正在用哪些应用。而云端的 OpenClaw 则发挥其复杂推理与多任务调度能力，负责长期运行任务、系统级 API 操作等核心工作。
我们可以通过两个真实的场景，来看看这种「端云协同」是如何比单一端侧更聪明的：
场景一：复杂文档的「端-云-端」接力
当你收到一份几十页的技术文档时，单纯的端侧模型往往读不懂深层逻辑，而单纯的云端模型又无法直接操作你的本地 App。
在「小万」的流程里，
端侧 Agent
首先接管，利用本地算力提取文档的关键信息；随后，任务流转至
云端
，由 OpenClaw 进行深度的逻辑梳理和摘要生成——这是手机本地算力难以企及的。最后，处理好的结论回传至手机，由
端侧 Agent
再次接手，询问你是否需要「发送给同事」或「保存到笔记」，并直接调用微信完成发送。
用户感知到的是一次流畅的服务，但后台其实发生了两次「端-云-端」的职能交接。
场景二：基于感知的智能通勤
早晨醒来，
端侧 Agent
基于本地传感器感知到「外面下雨了」，并读取了你本地日程中「早晨 9 点有会」的信息。
这些上下文被脱敏后发送给
云端
，云端大脑迅速规划出一条避开拥堵的打车方案，并决策出「需要提前出发」。
当方案确定后，指令回到
端侧
。此时，「小万」直接在手机本地唤起打车 App，自动填写目的地、选择车型，并停在支付确认页面等待你点击。
这种「端侧感知、云侧决策、端侧执行」的高效协同模式，既规避了纯端侧智能能力不足的短板，也解决了纯云端智能缺乏场景感知和隐私顾虑的痛点。
02
真正解决的难点：
算力、成本与隐私
从 Demo 走向实用，一定会遇到一堆硬问题。先说最现实的：
成本与效率
。
把智能体装进手机听起来很容易，但现成方案没法直接照搬。高频调用的日常场景里，Token 成本绕不过去；手机端还要算清楚内存、功耗、温度、延迟。你可以在云端把模型堆得很大，手机端必须把每一次 Token、每一次访存、每一次调度都算明白。
哪怕是 OpenClaw，也会疯狂消耗大模型服务的 Tokens。不少网友在社交媒体吐槽账单太夸张，很多专业用户一天就能跑出数百美元。如果让手机里的每一个小动作都去问一遍云端大模型，这在商业上是跑不通的。
「万象智维」给出的路径，是算法与系统的深度协同优化，重点做了两件关键技术工作。
首先，是对端侧推理框架的「极限压榨」。
既然是协同，端侧就不能太弱。「万象智维」开发了一套名为「OmniInfer-VLM」的框架，旨在榨干手机 NPU 的性能。数据显示，在不牺牲精度的前提下，该框架能让多模态推理速度相对传统 CPU 方案提升接近 20 倍。
这意味着，像屏幕识别、OCR 提取、简单的意图判断这些高频操作，完全可以在本地毫秒级完成，无需联网，既快又省。
在此之上，是以「行为」为核心的记忆系统。
并不是所有任务都需要「思考」。现实中，我们每天的点咖啡、打卡路径是高度重复的。每次都从零推理不仅慢，也更容易出错。
团队引入了一套记忆系统，将用户的高频操作路径抽象成数学模型记录在本地。当你第十次点同一种咖啡时，系统不再需要云端的大脑重新推理「怎么点」，而是直接调用本地的行为记忆，进行自动化执行。
这不仅让执行速度更快，更重要的是，它大幅减少了对昂贵云端算力的调用次数——据测算，这种机制能让平均推理延迟降低约 1.49 倍。
此外，还有隐私的「护城河」。
在 Agent 时代，隐私不仅是数据，更是行为。相比于部分方案将每一帧截屏都上传云端进行分析，端云协同架构提供了一种折衷的安全性：敏感的上下文（如微信聊天记录、支付密码页面）始终保留在端侧处理；只有经过脱敏、任务需要的抽象指令才会发往云端。这虽然无法做到 100% 的物理隔绝，但相比纯云端接管，它在架构上为用户保留了数据的「所有权」。
03
落地与生态：
清华系团队的工程化答卷
AI 硬件需要的是一种低算力、但在高频场景下仍然足够顺的解决方案。想走到日常使用，总要面对一个现实：算力不可能无限，体验却必须够稳。
目前，这套方案已经不仅仅停留在 PPT 上。根据产品信息，「小万」目前已实现了端侧持久化的上下文记忆，在完全依靠端侧自身算力配合云端调度的条件下，支持约 40 款主流应用，覆盖约 150 个场景任务。无论是打车、消费、支付等日常任务，还是规划相关日程，都可以通过「小万」来完成。
这组数字虽然不能等同于「全能 Agent」，但却勾画了一张清晰的工程化路线图：先把高频、可验证的任务做扎实，再把覆盖面铺开。
而在部署上，「万象智维」同样把「本地化」当成核心能力设计：「小万」的端侧任务主要利用手机本地算力完成；云侧会为每位用户开设独立的虚拟云服务。对有本地部署需求的企业用户，他们还提供了本地化部署 OpenClaw 的方案，通过 API 无缝接入「小万」，进一步降低隐私顾虑。
这套成熟的工程化打法背后，是雄厚的技术积累。「万象智维」依托清华大学端智能研究团队孵化成立，核心团队在清华大学计算机系任炬副教授与清华大学智能产业研究院李元春助理教授的长期指导下，在端侧模型轻量化与高效推理领域有着扎实积累。公司成立后首轮融资便获得来自星连资本领投的数千万元天使轮投资，也侧面印证了行业对其技术路线的认可。
04
未来：从人机交互到
Agent-to-Agent
如果说 OpenClaw 让我们看到「Agent 可以动手」的可能性，那么「小万」更像在回答另一个问题：当动手发生在更多形态的端侧设备上，智能体还能不能把事办完，并且办得让人放心？
未来的端侧 AI，或许不会局限在手机这一个形态上。眼镜、手表、甚至是未来的新型终端，它们本质上都是一个个「端侧 Agent」。它们各自拥有不同的传感器和执行能力（有的能看，有的能跑），而云端则是一个通用的「超级大脑」。
「万象智维」正在构建的，正是连接这两者的中间层——
Agent-to-Agent 的交互网络
。
在这套网络中，任务不再被绑定在某一台设备上，而是由云端统一规划，分发给最合适的端侧设备去执行。移动端 AI 的「动手时代」已经开场。真正的分水岭，或许不在于谁的模型参数更大，而在于谁能用最工程化的手段，把聪明（云）和靠谱（端）真正结合在一起，解决那些用户每天都要做、又最怕出错的琐事。
*头图来源：
万象智维
本文为极客公园原创文章，转载请联系极客君微信 geekparkGO
极客一问
你如何看待
未来的端侧 AI
？
热点视频
Sam Altman：Moltbook 或为一时狂热，但 OpenClaw 绝对不是。
点赞关注
极客公园视频号
，
观看更多精彩视频
更多阅读