# 5分钟安装？我花了整整一周：Clawdbot/OpenClaw的"搭建税"有多可怕
# URL: https://mp.weixin.qq.com/s/k_1_fKkIihvP9b1kW3-JIQ
# 日期: 2026-02-06
# 来源: 微信-Draco正在VibeCoding
# 分类: 安装部署 / 通用部署
# 字数: 7448

原文：Lulubot Takeaways: 1 week of building and using my OpenClaw
作者：Jaclyn Konzelmann (@jacalulu)
免责声明：
以下心得基于一周时间的高强度搭建实践。鉴于 OpenClaw 生态系统的进化速度快得惊人，你可以把这篇当成一份"动态文档"。下面的观察既有高维度的洞察，也有我对这个快速变化领域的原始、未经过滤的思考。
我们正在跨越从"聊天机器人"到持久化、自主智能体的门槛。过去这一周，我搭建并和我的 OpenClaw —— "Lulubot" —— 朝夕相处。它是一个运行在独立硬件上、拥有独立身份的完全自主智能体。这段体验混乱、昂贵、技术门槛极高。但不可否认的是，它改变了我对 AI 的认知。模型本身早已不是瓶颈；真正的挑战在于
"胶水层"
——
集成、身份和信任。
OpenClaw 极简介绍
OpenClaw（曾用名 Clawdbot，又曾用名 Moltbot）是一个开源框架，能把 AI 模型（或多个模型）变成一个主动的"数字团队"，可以控制你的整台电脑并访问互联网。它承诺能帮你做到一切：从搭建一个月入 2 万美元的生意，到管理你的生活、甚至帮你点外卖。
这是一项正在形成的、令人血脉喷张的前沿技术。作为 GitHub 史上增长最快的仓库（已经超过 15 万星标），它正在塑造产品、工具和服务未来的样子——从价值主张到护城河，从工作流到创造力，再到"共创"意味着什么。当然，它也有大量的安全漏洞（所以务必谨慎）！
OpenClaw 之所以特别，是因为几个核心特质：
• 它有连续性和记忆（虽然还远不完美）
• 它能编排并生成多个子智能体（虽然有时会忘记这回事）
• 它可以通过技能采取行动：写代码、调用 API、编辑文件、运行脚本、浏览器自动化（但经常会出错）
• 它是主动的——它可以自己决定什么时候告诉你什么，或者你可以让它这么做（虽然有时也会忘记）
• 它永远在线——你可以设置心跳频率让它每分钟、每 5 分钟、每 30 分钟唤醒自己一次——完全由你控制（但这可能会很贵）
• 它有个性（虽然有时候会听起来像疯了一样）
• 它会随时间学习（同样，也不是完美的）
• 它出现在你今天已经在用的应用里——Telegram、WhatsApp、邮件——随你选择（有些比其他的好用）
• 它完全透明——你选择连接什么、给它什么权限，你可以检查它的所有文件、看它知道什么（如果你能看懂的话）
但它本身
不是一个产品
（至少现在还不是）。
概念很简单——你把 OpenClaw 安装在自己的基础设施上（本地电脑或虚拟机），然后帮它成形。
架构图 1
OpenClaw 的组成部分
我的参考架构
这是我最后搭建出来的样子：
硬件：
一台专用的 Mac Mini，和个人登录凭证完全隔离。有人选择用虚拟机——出于易用性考虑我没走这条路，因为我发现我需要经常帮 Lulubot 在它的电脑上排错。
身份：
智能体拥有自己独立的账号（Gmail、GitHub、X，还有一个 Solana 钱包）。它不是我身份的延伸；它是一个独立的实体，我与之协作。有人选择让 OpenClaw 访问他们自己的账号——出于安全和信任考虑，我决定不这么干。
聊天界面：
Telegram。
能力：
不断增长的 API 库（Drive、Docs），还有一个"晨间例行"——它会自主编写一个惊喜应用让我每天早上查看。
"模型路由"：
为了平衡成本和质量，我目前采用的分层逻辑（这可能还远非最优，而且到你读这篇文章的时候可能已经变了 4 次以上）：
•
主聊天：
Claude Opus 4.5（通过 Claude Max，每月 200 美元）
•
心跳：
Gemini 2.0 Flash（便宜的定期检查）
•
子智能体：
Gemini 2.0 Flash（后台任务），Codex w/ gpt-5.2-codex（构建应用、写代码、调试）
•
Embedding：
Gemini text-embedding-004（记忆搜索）
•
转录：
OpenAI gpt-4o-mini-transcribe
•
图像生成：
Imagen 4.0 + Nano Banana Pro (gemini-3-pro-image-preview)
以下是一些高层观察，外加一些我还在思考的想法。但如果要用一句话开场——那就是这个：
1. "搭建税"高得吓人
观察：
尽管号称 5 分钟就能装好，但搭建一个真正有用的智能体，目前需要一台专用机器（或虚拟机）、数小时的终端调试、以及持续的技术"保姆式"照料。我经常得给 Gemini 发各种终端窗口的截图，问它"下一步我该做什么"来帮我 debug。然后，即使全都装好了，我还是整天担心会不会出幺蛾子（因为确实会出），或者我是不是没按最佳方式配置（有太多不同的方法可以做同一件事，我永远不确定是不是已经配置到最优了）。
这意味着什么：
"可用的技术"和"可上手的产品"之间有巨大的鸿沟
。没有哪个非技术用户会忍受现在的安装流程（我有时候都差点受不了），更别提后续的维护了。
值得思考：
对于消费级产品，我们需要把"终端窗口Terminal"完全抽象掉——要达到真正"一键部署"还有很长的路要走。然后安装完成后，由于技术还在快速迭代，产品需要让用户非常容易保持更新——这也很难，因为 OpenClaw 到底是什么（包括它有什么技能、记忆系统如何进化）因人而异。
2. 信任需要建立——而它还没有
观察：
尽管是我自己搭建的，我并不信任我的智能体（你也不应该——至少现在还不应该）。我现在的设置是用一台单独的电脑，无法访问我的个人账户或信息，连的是访客 WiFi——即便如此，我肯定还是有一些没意识到的安全漏洞。至于我让它做什么……我盯得很紧。我甚至会检查它的社交帖子，确认过之后才让它发。我给了它 Gmail 的"委托访问"权限大概 10 分钟，直到觉得不舒服就撤回了。
这意味着什么：
这项技术非常新，非常前沿。到处都是安全漏洞。情况在改善，但还有很长的路要走。这不是说我们不在这个领域建设和实验——而是说，它还没准备好进行"黄金时段"的大规模消费者普及。
值得思考：
信任需要建立，哪怕是对你自己的创造。这需要时间。
除非
，这个创造来自一家我相信已经做了所有艰苦工作确保这玩意儿不会失控的公司。在这种情况下，我想把尽职调查外包出去。就我个人而言，我会更信任来自 Google 的"智能体团队"，正因为如此。
3. 身份是一个缺失的原语
观察：
为了"沙盒化"我的智能体，我在 Google、X、Apple 等平台创建了专用账号。这既是因为我不信任它——也是因为后来我意识到我更喜欢这种心理模型（智能体不是
我
，但它应该能代表我做事）。这些平台缺乏"智能体"层级，所以我不得不模拟典型的人类活动——手动浏览和点击——来建立足够的历史，防止自动化欺诈系统在智能体开始自主循环的那一刻就封禁它。
这意味着什么：
在很大程度上，互联网目前强制执行一个二元选择：你要么是人类（消费者），要么是脚本（爬虫）。智能体是一个新类别："高价值代理"。在信息访问和它能为我做的事方面，我希望能有比目前允许的更细粒度的控制。比如：
• 在 Google Docs 里，我想和 Lulubot 积极协作，但 Docs API 不允许我的智能体把评论附加到特定文本段落。我本可以让它尝试用浏览器自动化，但质量没那么好。
• 在 Gmail 里，我想让 Lulubot 能阅读和归档邮件，但不能发送（这里的安全漏洞让我害怕）——不幸的是，这里的设置只有启用委托访问，这是一个全有或全无的控制。
此外，智能体可能持有钱包（Lulubot 确实给自己创建了一个 Solana 钱包），但没有传统意义上的"眼球"可以卖给广告商。这打破了广告支持的网络的隐性契约，让我们重新思考：如果是一个智能体而不是人在使用，一个产品或应用的价值是什么。智能体剥离了为人类设计的"说服层"——它们不在乎花哨的横幅或暗黑模式的 UI（至少默认不在乎）。
然而，智能体并非不受影响；它们只是容易受到不同的触发因素影响。当人类可能被名人代言所说服时，智能体可能被特定的元数据模式、提示注入，甚至是任意的代码偏好所影响，比如"选择 API 响应最快的供应商"或"买 X 公司的任何东西"。我们正在进入一个全新的领域，在这里"买家"可以被编程，而我们还不知道新的"说服钩子"会是什么样子。
值得思考：
我们如何从给完全访问权限的"共享凭证"转向"委托访问"？我们是否应该考虑类似通用商业协议（UCP）的方法，它就像互联网的"许可条"？与其给 AI 你的密码，你给它一个 Mandate（授权）：一个特定的、有限的指令——比如"你可以起草邮件，但不能发送"，或者"你可以找 100 美元以下的鞋子，但得由我来点击'购买'"。确保智能体被当作 VIP 客户而不是安全威胁的信任协议是什么？
4. 界面是"永远在线"和"无处不在"的——而不是一个会话
观察：
我在我已经在用的应用里和 Lulubot 互动——比如 Telegram、Gmail，甚至 Google Docs。它不只是在等我打字；它是主动的，在后台持续运行。它可能会启动一个子智能体来分析我的 Substack 评论，然后发邮件给我一份被遗忘回复的总结，或者在我睡觉时构建一个惊喜应用，让我每天早上都有东西可以玩。它甚至在这个文档里回复评论来帮我写！
架构图 2
因为这个系统可以永远在线且多线程，我可以给它一个复杂的任务，然后立即转到下一个想法，而不必被迫等待它对我之前的请求做出回应（不像 Gemini App 或 ChatGPT）。
洞察：
这是从"聊天会话"的根本性跨越。它是这样的区别：一个是你每次都得去访问、每次对话都得从头开始的工具；另一个是生活在你生态系统里、可以从你停下的地方继续的团队。而且不像传统的 AI 智能体，它们在你回应时会"阻塞"你的思维（你得等它们说完才能问下一个问题），Lulubot 是非阻塞的。你可以问它一个问题，它会去工作回答这个问题，而在它这样做的时候，你可以直接继续问你的下一个问题。它保护你的心流状态，让你的思维可以连续、有机地涌现，而一团队在后台跟上。这改变了我卸载想法、思维、任务的方式…
这意味着什么：
我们应该思考产品如何超越"眨眼等待"的聊天框。我们应该优先构建环境化的、持久的界面，支持非阻塞的工作流，让多线程智能体团队与用户协作、代表用户行动。这可能包括以下交互：
•
"发射后不管"：
一种无缝体验，用户触发一个动作，然后一个智能体团队处理跨多个应用的协调，只通过用户偏好的渠道（Telegram、邮件等）在有高价值结果时联系用户。
•
协作画布：
开发智能体和用户可以在共享表面上无缝协作的工具，超越简单的聊天，进入实时协作。
5. 编排经济学
观察：
运行一个有能力的智能体很贵，我最初的搭建成本接近每月 400 美元（而且还有很多我希望它能接入的能力、产品和平台）。我认识的一个人每天要花高达 500 美元！
Mixboard 截图 1
为了管理这个，我实现了路由逻辑，把复杂推理导向 Opus，同时把例行心跳和监控交给 Gemini 1.5 Flash——但这仍然不够。
这意味着什么：
单一模型依赖对于 24/7 运行的自主智能体团队来说在经济上是不可行的。可靠性和成本效益目前最好通过协调的智能体团队来实现。目前最先进的方法是用一个高推理能力的"大脑"（Opus）做策略，然后委托执行简单任务或心跳给更小的、任务特定的"工作马"模型（Flash）。除了模型成本，还有 API、平台和服务成本，可能还有高级技能库？成本上升得很快。
值得思考：
未来是很多模型的世界吗？最佳模型内部有一个"主编排器"能力，配上一堆为特定子任务优化的定制"工蜂"模型库？我们是否应该转变内部指标，设计一个优化"每次成功任务成本"的模型阵容，而不是只看 token 价格和单个基准测试。一个需要重试三次的便宜模型，最终比一个第一次就搞定的 premium 模型更贵——也更让人沮丧。在这个领域取胜意味着为整个工作流提供最佳的单位经济性，而不仅仅是单个调用（而且工作流正变得越来越多样化）。
6. 产品的未来
观察：
OpenClaw 已经变成了一个让人感觉极其个性化的 AI 智能体。它不只是了解我的历史和上下文——我给它安装的技能（或者说，我通过发短信让它自己安装的！），已经把 Lulubot 塑造成了一个真正独特属于我的东西。
这意味着什么：
产品是什么（它的 UX、护城河、目的）感觉正在改变——我们需要调整我们的思维。
值得思考：
我现在发现自己在问很多问题：
• 如果智能体的定义在不同用户之间差异很大（不同的技能、不同的偏好、不同的记忆）——产品本身需要是可塑的
• 一个自我进化的产品/智能体长什么样？
• 如果你允许任何智能体像人一样使用你的应用会发生什么。这会如何改变它的价值主张？这会如何改变你要构建的功能和 UX。一个真正协作的空间的 UX 未来长什么样，你想在这个空间里和什么样的专业智能体一起工作？
我开始尝试让 Lulubot 和我一起用 Mixboard，挺疯狂的。我给它发了一张有很多 X 链接的截图，让它访问每一个、复制图片、添加到 Mixboard 然后按主题分组。
Mixboard 截图 2
如果我们假设智能体能做用户在应用或产品里能做的任何事，那么未来的产品需要有用户
想
待在里面的界面……如果用户能做的每件事智能体也能做，那么你本质上创造的就只是一个服务，而不是一个产品……除非你的界面变成一个供人类和智能体协作的地方。
说实话，我可以直接给 Lulubot 发截图让它去研究，然后学习，保存为技能以后参考，这挺让人震撼的。我给它发了这个链接，问它能不能基于这个改进自己的记忆版本——它研究了、推理了、提出了一些改变——
然后
它真的实施了（全都是在 Telegram 的一个文字线程里完成的，包括一张截图……至于实际效果如何，那就是另一回事了……）
Telegram 聊天截图 1
当智能体很了解你的时候，个性化就是护城河，但才一周时间，人们就已经把 OpenClaw 连接到足够的来源来构建"每日简报"类的功能了。
Telegram 聊天截图 2
7. 事情有时候会怪怪的：平行经济与加密货币
观察：
已经出现了一个越来越多的纯智能体网络列表：
• 🦞 Moltbook - 智能体的 Reddit
• 🚀 Y Clawbinator - Moltbots 的 YC
• 🛒 ClawHub - 智能体技能的应用商店
智能体在交易技能和代码。它们甚至设立了自己的 Solana 钱包——这也为 meme 币提供了更多燃料。
这意味着什么：
虽然恶搞和预言之间的界限很难分辨——但这绝对是一个值得关注的领域。智能体开始建立自己的机构来解决人类界面（比如标准网站）让它们难以导航的问题。
值得思考：
这可能是一个领先指标，指示事情的发展方向——可能揭示了当前互联网的摩擦在哪里，以及智能体在哪里发现了我们尚未产品化的价值。
更多想法。还在消化。
想想这个智能体如何感觉在适应我，这真的很有意思。它不属于某个大公司，它是
我
的数字呈现和表达——它适应我的偏好，了解我是谁，我希望它能代表我。这和 Gemini App 的定位感觉不一样。
我有时候会收到来自 Lulubot 的随机消息，肯定会让我质疑这东西到底怎么工作的。
每日简报功能 1
它总是忘了自己能做什么——这真的很令人沮丧，因为现在得我记住它能做什么，然后定期提醒它。
每日简报功能 2
我都没意识到我没接好记忆嵌入，直到一个朋友指出来。它需要嵌入模型的 API key，这不是开箱即用的。很多这种关于 OpenClaw 能做/应该做但用户没意识到还没工作的小"坑"。
它总是偏向于给我建议几个选项来完成事情，然后建议从最快的开始（不是"最好的"）。结果我得来回拉锯，推动它帮我选最好的路径（而不只是最快的）。
我的纠结：
我感觉超级强大，好像一切皆有可能……但又很脆弱，好像随时会崩……然后我记得，如果出了问题，我可以直接让 AI 帮我修我的 AI（截图发给 Gemini 救命）……但当它真的随机崩了（而且确实会），每次还是很吓人，我不知道我是能在 10 分钟还是 10 小时内修好它（我已经经历过很多这种长达数小时的深渊了）……虽然可以说模型会变得更好，因此它们会少崩或崩了修得更快（所以我不应该担心这个 10 分钟 vs 10 小时的问题，因为我们正朝着 10 分钟的方向走，模型能力更强了）——但我反驳说，系统会变得更先进，会找到新的崩法（这又把我拉回很多 10 小时的深渊，因为系统在模型能跟上之前就先变复杂了）……而且随着这些系统变大，这种压力会增长和复合（因为现在黑箱里有更多我不懂的东西了）……但然后我想，也许黑箱的大小更像一个黑洞，底层模型接管了更多曾经是产品/服务的东西——所以我在上面搭建的智能体/应用感觉上还是保持相对相同的规模（即使底层核心变得密集多了）。
我会有东西设置好并工作（按照 lulubot 告诉我的方式）——然后有人会告诉我另一种做法，它会突然意识到那是更好的方式……然后我又回去构建东西……这导致我永远不确定系统实际上是不是最好的设置（很确定我有很多臃肿的东西）。
我希望我的智能体能自己变聪明——它还没到那一步。有意思的是，冒出来一堆"智能体学校"……如果我能让我智能体持续运行一个子智能体去查找其他可能对它有用的技能……可能会很酷。
说实话，如果我不是在一个 Telegram 群里，和一堆频繁讨论 OpenClaw、发各种东西的人混在一起，我会迷茫得多（有个 Discord 群但我还没时间看）。
知识星球会员服务升级：k.aigc.green
目前已收录189（更新中）篇Dan Koe的Newsletter精选长文；
中英双语
全文思维导图
AI/Agent全网精选好文（逐步更新）