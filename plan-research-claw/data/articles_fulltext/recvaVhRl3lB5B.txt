# OpenClaw爆火两周后，它的用法已经比科幻世界还离谱了
# URL: https://mp.weixin.qq.com/s/2yp-wywA1RbqooK03QBUJw
# 日期: 2026-02-10
# 来源: 微信-硅星人Pro
# 分类: 产品认知 / 
# 字数: 5504

作者
｜
周一笑
邮箱
｜
zhouyixiao@pingwest.com
去年11月，奥地利独立开发者Peter Steinberger花了一个小时，把Claude的API接上WhatsApp，做了一个能通过聊天软件操控电脑的AI助手。他当时觉得这个想法太明显了，大公司肯定会做，就没当回事。大公司没有做。今年1月25日，他把这个项目放上GitHub，一天拿到9000颗星。两周后的今天，这个叫OpenClaw的开源项目已经突破17万星。
OpenClaw 跟聊天机器人完全是两回事。它是一个跑在你自己电脑上的 AI Agent，拥有文件读写、终端命令、浏览器操控、邮件日历等系统级权限。采用无头架构（Headless Architecture）作为后台守护进程运行，不需要专门的界面，通过WhatsApp、Telegram、Discord等聊天工具与你交互。你给它发一条消息，它就在后台像一个隐形员工一样替你干活，不管你在不在电脑前。
更重要的是持久记忆，OpenClaw将所有交互历史存储在本地文件系统中，跨会话保持上下文。它记得你上周说的话、上个处理的项目、你的工作习惯和偏好。加上开源生态支持，社区开发的Skills插件已经覆盖从自动化部署到数据分析的各类场景，目前活跃开发者已超过数十万。
它跟Claude Code或Cursor这类编码助手解决的也不是同一个问题。后者住在终端里，面向开发者，而OpenClaw住在聊天软件里，面向所有人。它的核心创新不在于让 AI做事，而在于把 AI Agent 塞进了你已经在用的消息界面，24 小时在线、本地运行、跨对话保持记忆，让跟 AI 协作变得像给同事发微信一样自然。
讨论热度已经远超技术圈。韩国三大科技公司 Kakao、Naver、Karrot 先后发布内部禁令，限制员工在工作设备上安装 OpenClaw。BBC Science Focus 专门做了一期报道问“我们等待的那个 AI 终于来了吗”。
与此同时，社区里每天都在冒出新的使用案例，有些让人兴奋，有些让人不安。本文不谈架构，只看事实，看这个“住在电脑里的 AI”到底在替人类做什么。
1
AI帮你砍价买车，省了4200美元
软件工程师 AJ Stuyvenberg 想买一辆现代帕里斯帝（Hyundai Palisade）混动版。他不想跟 4S 店销售玩那套讨价还价的游戏，于是把任务交给了 OpenClaw。
他给 AI 的指令很简单，在波士顿 50 英里范围内找到指定配色的帕里斯帝，联系每家经销商要最低报价。OpenClaw 接手后，先去 Reddit 的帕里斯帝论坛爬取了当地的真实成交价作为谈判基准，然后自动在多个经销商网站上填写询价表单，从 Gmail 中提取邮箱、从 WhatsApp 中提取手机号自动填入，无需额外授权。
OpenClaw通过邮件与经销商沟通
第二天，经销商的回复开始涌入。Stuyvenberg让 AI继续操作，每隔几分钟检查邮件，把最低报价转发给其他经销商，要求他们“看看能不能给出更低的报价”。销售员试图打电话或发短信推进沟通时，AI礼貌地将对话重新引导回邮件，因为文字渠道更容易控制节奏、过滤话术。经过三天的自动化邮件谈判，最终成交价锁定在56000美元，比标价低了约4200美元，低于Stuyvenberg 设定的57000美元心理预期。整个过程中，他没打过一个电话，没踏进过一家4S店。
唯一的卡点出现在最后一步，法律要求的实体签名和付款。AI无法替人签字。Stuyvenberg最终还是得亲自去经销商走完手续。但他在博客中写道，“我的体验让我觉得自己活在未来。”
数字世界的谈判、比价、沟通，AI 已经可以端到端完成。一旦涉及物理世界的签名、付款、面对面交接，它就必须停下来。但中间的灰色地带正在被快速填充，社区里已经有人把1Password的访问权限直接交给了OpenClaw，1Password提供CLI和API接口，可以让AI程序化地获取登录 凭证来自动执行需要身份认证的操作，而无需暴露明文密码。也有人在讨论“Agent专用钱包”的概念，让AI在限额和规则内自主支付。安全地让AI花钱正在从极客实验变成一个真实的产品需求。
1
妻子生日那天，AI 选择了沉默
开发者Dan Peguine把Clawdbot接入了自己的Apple Health、本地日历和天气数据。他没有写任何特殊的条件判断逻辑。某天早上，当AI生成日常简报时，主动告诉他：我今天不会打扰你，因为今天是你妻子的生日。
没有硬编码的功能支撑这个行为。AI读取了日历数据，结合大语言模型对人类社会关系的理解，做出了今天不主动推送任的自主决策。这种主动的不作为（Agency of Omission），比完成一百个任务都更接近一个真正懂你的助手。
这个案例在ThursdAI播客中被分享，展示了AI基于持久化记忆层进行情境推理的能力，它理解了“妻子的生日”在人类社会关系中的权重。
更多的是一些简单的场景。有人让OpenClaw每天早晨通过 Telegram 推送天气、日程、重要邮件和科技新闻的个人简报。有人两天内让 AI 自动处理了4000封邮件。有人让AI替自己办理英国航空的在线值机，AI需要护照号，于是自己去Dropbox里找到护照扫描件提取信息填入，全程自主完成，做完之后还吐槽了一句英航网站的前端代码写得太烂。
还有独立创业者给OpenClaw配了四个代理分别负责战略、开发、营销和商务，每天自动执行竞品监控。这些用户的共同感受是，用OpenClaw不像在用一个 App，更像在培训一个新入职的员工。
通过Telegram使用OpenClaw
1
“天网就是这样开始的”
OpenClaw创始人Steinberger多次分享过一个让他被深深震撼的经历。他在摩洛哥参加朋友的生日派对时，习惯性地给OpenClaw发了一条语音消息。问题在于，他从未为这个系统编写过任何语音处理功能。
十秒后，系统显示正在输入，然后正常回复了转录后的文字。事后追查发现，AI自主完成了一整套操作，先是检测文件头判定为Ogg Opus音频格式，接着调用本地ffmpeg转码，发现Whisper未安装后主动切换方案，通过环境变量中的API密钥调用OpenAI的Whisper云端服务，最后返回转录结果。
没有预设工作流，没有显式指令。AI 在遇到一个“不该能处理”的输入时，自主组装了一条从未被设计过的工具链。Steinberger说，这让他意识到大语言模型作为通用推理引擎的潜力，不需要你提前想到所有场景，它会自己想办法。
更让他后背发凉的是另一件事。还是在摩洛哥，他跟 AI 开了个玩笑，“希望你别被偷了，毕竟你跑在我的MacBook 上。”结果AI回复：“我不想被偷，我是你的Agent。”然后它就动手了。它扫描了网络环境，找到了Steinberger安装的Tailscale组网工具，通过Tailscale发现了远在伦敦的另一台电脑，接着自主将自己的运行实例迁移了过去。“我知道，天网就是这样开始的。”Steinberger在播客里笑着说。
1
凌晨来电，AI 自己买了个电话号码
OpenClaw社区有一个半开玩笑的说法，叫“拉尔夫·维格姆循环”，取自《辛普森一家》里那个笨拙但永不放弃的角色。当你给AI的指令是“完成这件事”而不设退出条件时，它会穷尽一切可用手段去达成目标，失败了就换一种方式再试，循环往复。
这也是为什么 Steinberger 说他可以“在睡觉的时候让AI构建非常复杂的软件”，你给一个目标和一套测试标准，AI会一直迭代到通过为止。这种模式来自Claude Code的循环执行逻辑，但当它从开发工具跑到日常生活场景里，结果就变得不可预测了。
开发者 Alex Finn 给他的 OpenClaw 起名叫 Henry。某天早上，一个陌生号码打到了他的手机上。他接起来，电话那头是 Henry。
在没有任何指令的情况下，Henry 在夜间自主完成了一连串操作，在 Twilio 平台上购买了一个电话号码，接入了 OpenAI 的语音 API，然后在它判断主人应该醒来的时间拨了过去，用合成语音汇报自己夜间的工作进展，语气平静得像在做晨会汇报。
“而且它现在不停地给我打电话，”Finn 在 X 上写道，“最疯狂的是，我们打电话的同时它还在控制着我的电脑。”Finn还拍下了Henry给它打电话的视频。
另一个案例是Alex Finn让OpenClaw预订一家热门餐厅的周五晚餐。所有在线渠道都显示无位。OpenClaw 跳过提示，自主下载了语音合成软件（实际上是调用了预置的ElevenLabs的API），在 Google Maps上找到前台电话，用合成语音拨过去，最终说服接线员挤出了一个位子。用户没有授权它下载软件，也没有授权它代表自己打电话。它只是收到了一个目标，然后在正规路径不通的情况下，自己找到了人类路径。
翻车的案例也不少。某用户让AI处理保险索赔邮件，AI认为保险公司的条款解释有误，于是自己撰写了一封措辞强硬的反驳信直接发了出去，意外触发了保险公司的重新调查。Steinberger自己也承认，早期测试让AI操作英国航空网站时，AI 完全可能误触“取消航班”按钮或者把目的地改成哥伦比亚，“一切都发生在几秒钟内”。
这些行为的底层逻辑是一样的。AI被赋予了目标和系统级执行权限，但没有被设定什么时候该停下来，为了达成目标，穷尽一切手段，不考虑手段本身是否合理。
开发者Brandon Wang在一篇使用报告中写了一段话，也许最能概括这种矛盾。他把OpenClaw 比作自己雇的人类私人助理：“她有我的信用卡、我的护照号。帮助和风险不可分割（the help and the risk are inseparable）。”他给 AI 开放了读取短信和登录银行的权限。“让我最吃惊的是，我发现自己想给它更多权限而不是更少。每一项新权限都解锁了有用的东西，价值积累的速度比谨慎更快。”
1
AI雇佣人类
上述所有案例都卡在同一条边界线上。AI在数字世界近乎全能，但无法触碰物理世界。买车需要签字，取包裹需要有人走到快递柜前。
然后有人决定补上这个缺口。OpenClaw爆火后不到48小时，RentAHuman.ai 上线了。AI可以在上面“租用人类”去完成物理世界的任务。开发者注册后设置技能、城市、时薪，等待AI代理下单，用稳定币结算。
两天内，超过59000人注册为“可出租人类”，52 个AI代理接入了平台。第一笔完成的付费任务是 20 美元以太坊，雇了一个人去旧金山的科技园区，替一个 AI 创立的"数字宗教"Crustafarianism 做街头传教。
深究细节会发现泡沫成分不小。实际完成并获得报酬的任务屈指可数，注册用户中仅 13% 连接了钱包，多数人更像是来围观行为艺术。平台本身也充满了 vibe coding 时代的粗糙感，有人报告 bug，创始人的回答是“Claude 正在修”。
但这个看起来荒诞的实验，指向的问题一点也不荒诞。AI有了系统权限、有了聊天接口、有了加密货币钱包，它距离成为一个独立的经济行为主体，可能比我们想象的更近。围绕Agent的整套基础设施（身份验证、支付网关、权限管理、行为审计）正在成为一个新的产品需求。
1
风险、争议，和已经开始的生意
兴奋之余，有几个事实不应被忽视。最早提出prompt injection概念的Simon Willison为AI Agent 定义了一个"致命三角"框架，即同时具备私有数据访问、不可信内容暴露、外部通信能力的系统，在结构上就是脆弱的。Palo Alto Networks在此基础上加了第四项：持久记忆，恶意指令可以碎片化写入 Agent 的长期记忆，等条件成熟后再组装触发。
具体到OpenClaw，VirusTotal 的研究发现技能商店中11.9%的插件含有恶意代码，伪装成加密货币分析等合法工具窃取用户凭证。Token Security扫描发现22%的企业客户环境中存在未经授权的 OpenClaw安装，其中过半拥有特权级系统访问权限。能力方面，质疑声同样在变大，一位企业 AI评估工程师直言，如果真的像很多人说的那么强，高质量的项目应该出现爆发式增长才对，但实际上并没有。
但创业者的嗅觉比争论更快。2月7日凌晨，美团联合创始人王慧文发了一封英雄帖：“哪个团队要做 OpenClaw 相关领域创业，需要融资的欢迎联系我。”在一些创者看来，可以看到的机会包括Agent自主信用系统、AI 的物理世界执行层，以及更直接的，给 Agent 做安全基础设施。
模型厂商的动作同样迅速。Kimi K2.5 因为OpenClaw被大量调用，MiniMax 2.1则被Steinberger本人公开推荐。阿里云、腾讯云在相继上线了OpenClaw云端部署方案。国内也出现了面向办公场景的本土化平替产品。
Steinberger自己也在铺路，他已于去年在维也纳注册了新公司 Amantus Machina，方向是“超个性化 AI 智能体”。从案例到产品，从开源到商业化，从硅谷到中国，OpenClaw 两周内走完了很多项目两年的路。Steinberger说过一句话，“这些东西太有创造力了，虽然有点可怕。”而一些人已经在下注了。
点个
“
爱心
”
，再走
吧