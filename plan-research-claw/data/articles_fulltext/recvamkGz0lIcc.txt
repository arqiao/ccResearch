# OpenClaw、Moltbook爆火，算力如何48小时内扩到1900张卡
# URL: https://mp.weixin.qq.com/s/9PG0YN8qTBhSKgrL5C1eqg
# 日期: 2026-02-06
# 来源: 微信-夕小瑶科技说
# 分类: 产品认知 / 
# 字数: 2492

过去一周，我看着三波 AI 应用的流量冲击波，一波比一波猛。
第一波是 OpenClaw（原名 Clawdbot），一个开源 AI 助手，在 GitHub 上 19 天拿下 11 万 +star，科技圈刷屏。
第二波是 Moltbook，一个 AI 专属社交网络，上线两天声称 150 万 AI agent 涌入。结果数据库不安全，平台被迫临时下线修漏洞。
第三波最离谱——RentAHuman.ai，一个让 AI 雇佣真人干活的平台，上线第一晚就有 130 人注册，包括 OnlyFans 模特和 AI 创业公司 CEO。第二天注册量冲到 1000+，服务器直接被挤爆了。
这仨产品说明了几个事情——
Vibe coding 的产品也可以火；
没有 PR 预算，没有投放计划的产品也能火；
流量一上来，要么服务器崩溃，要么被迫临时下线，要么让 AI 来救场修 bug。。。
随着 AI 编程能力的加强，出现这种突然爆火产品的频率正在加快。
春节马上就到了，最近看群里转发红包都疯了。究其原因是腾讯、百度、阿里、字节四大厂同时在搞春节 AI 红包大战。
腾讯元宝拿出来 10 个亿，百度拿出来 5 个亿，阿里千问拿出来 30 个亿，字节豆包直接拿下央视春晚独家的 AI 合作伙伴，除夕夜当天光互动人数保守估计都要几个亿。
这些是大厂，扛住流量应该都不是问题了。但是春节这波流量恐怕不只是大厂的狂欢吧，很多中小 AI 应用也在憋着春节期间冲一波。
光我手上知道至少好几个团队，团队都不打算回家了，都在憋着春节期间上新功能、做活动、冲流量。
今年流量暴增不是没可能，春节是全年流量最集中、用户最闲、传播最快的黄金窗口。说不定你的产品就火了呢。
问题来了，如果你的 AI 产品在春节期间突然像 RentAHuman 一样，第一天 130 人，第二天 1000 人，第三天可能 1 万人——
你的服务器撑得住吗？
这不是温和的增长曲线，是 GPU 集群瞬间打满的突发情况。
8 点日活还是 5000，9 点突然涌入 5 万人。请求开始排队，生成速度从 3 秒变成 30 秒，然后是 502 报错，然后服务器宕机。
但是，用户不会等你慢慢扩容。他们会吐槽、离开，然后再找回来就难了。
所以，你备好卡了吗？或者找好可以支撑你快速扩容的平台了吗？
如果没有，可以看看我之前推荐过的
共绩科技的弹性算力平台。
这个平台，主打是弹性， 流量高峰来了，算力自动跟上；高峰过去，资源自动释放。
这个特点很适合小型团队，尤其是 AI 产品初创团队。只需为实际使用量付费，无需为“可能用得上”的峰值容量提前买单。
而且成功支撑过爆火的 Remy。
Remy 这个案例我之前有关注过。去年华为 HarmonyOS 6 发布会，Remy 作为首发应用亮相。现场演示的功能是用手机拍一段环绕视频，就能生成可以 360° 查看的 3D 空间。
发布会结束没几个小时，Remy 就冲上了华为应用市场第一。
然后问题来了——50 小时内涌入 50 万新用户。每个用户上传的视频都要做 3D 建模，每一个请求背后都是 GPU 在跑重型推理任务。
如果按传统方式硬扛，Remy 得提前备好上千张 GPU 卡。但这不现实:
提前买，不知道发布会效果，万一不火，卡就闲置了。
临时买，来不及，等采购完、部署完，热度早就过去了。
租固定规模的云 GPU，还是那个问题，不知道该租多少。
关键时刻，Remy 背后的算力支撑方共绩启动了秒级响应。具体操作是这样的:
Remy 把 3D 推理服务做成 Docker 镜像；
接入共绩的 Serverless GPU 平台；
设置好自动扩缩容策略(比如单个节点的并发请求数、延迟时间等)；
剩下的交给平台。
48 小时内，支撑 Remy 的 GPU 集群从百卡规模自动扩到 1900 张卡。流量高峰时自动加机器，峰值过去自动回收。
全程没有大面积宕机，用户体验很稳。
这个案例最打动我的点是什么？
不是 1900 张卡这个数字，而是
48 小时内完成扩容
这件事。
传统方式下，就算你有钱买卡，从采购到部署到调试，少说也得一两周。等你准备好了，热度早凉了。但共绩这种弹性平台，你不需要提前备卡，也不需要自己运维。流量来了自动扩，流量走了自动缩。
而且只为实际使用量付费。Remy 那 50 小时的流量高峰，可能只占全年时长的 1%，但如果按传统方式备 1900 张卡，那 99% 的时间这些卡都在吃灰。对个人开发者和小团队来说，这个模式最划算，更友好。
你不需要一上来就投几百万买 GPU 集群，也不需要养运维团队 24 小时盯着服务器。
共绩平台做了几件事:
标准化部署：
Docker 镜像直接上传，预置了主流 AI 框架，不用折腾环境。
自动扩缩容：
回传链接不变，按 QPS、响应时间等等指标自动调整实例数量。
按秒计费：
GPU 按实际使用时间计费，用多少付多少。
具体怎么用，我之前用过他们的平台，流程比其他平台都简单，0 运维经验的人也方便上手：
把你的推理服务做成 Docker 镜像
选 GPU 规格，设置扩缩容策略
一键部署
部署完之后，平台会给你一个 API 地址。你的应用调这个 API，后面的算力调度、实例扩缩，全部自动处理。
算力这个东西，在 AI 时代越来越像水电了。平时你不会觉得它有多重要，但流量一上来，它就是硬瓶颈。
而且，现在这种突然爆火的概率越来越高，AI 编程能力变强,一个人几天就能做出爆款产品。社交传播速度变快，一条推文 6 小时就能触达百万人。用户尝试成本变低，看到新东西立刻就想试。
你不知道哪天突然就火了。可能是某个大 V 转发，可能是某个功能戳中痛点，可能是某个 timing 刚好踩对。
但如果那一刻，你的服务器撑不住，那就太亏了。
春节在即，如果你也在准备冲一波流量，可以提前测一下自己的服务器能扛多少并发。
如果心里没底，不如早点接入一个弹性平台做备份。至少流量真来了，你不至于手忙脚乱。
最后，祝大家的 AI 产品都能接住流量！