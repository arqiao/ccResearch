标题: Skill创作手记：3小时将微信聊天记录用Claude提取成【有价值的案例库】-Plus版 
日期: 20260129
原文: https://mp.weixin.qq.com/s/FzYISkLYbpv6gVjDlxXWUA

 id="js_content" style="visibility: hidden; opacity: 0; "> Part 1: 真实痛点-“客户问得太碎了” 上期项目，我是为了自己沉淀知识库解决了“ 群聊聊天记录提取链接 ”的问题——把微信群里分享的文章链接自动提取出来，导入飞书知识库，并作出可视化报告。 今天解决的问题，是基于私聊聊天记录提纯咨询问题。 （看似很垂直，实际应用场景更广了，后面会详细分析） 起因是近期服务的一个客户——想让我帮他把客户的聊天记录提取咨询问题整理成知识库，给团队学习。 这些咨询都发生在 一对一的私聊 里。 他很苦恼： 前期客户少的时候，看完整的聊天记录没问题，可以了解全貌。但时间长了，咨询量越来越多，你想让新来的团队成员学习，单独选取某些问题深入研究，迭代团队知识库，不可能让他把所有的聊天记录都翻一遍吧？“ 这次的需求和上次有了本质区别： 上次 ：公开群聊的 链接提取 。 这次 ：私聊场景的 问答内容整合 。 他要的，是把那些有价值的咨询信息，从海量的对话中整合出来，共享给整个团队。 但私聊咨询有个致命特点—— 客户问得极其零散 。 客户不会一开始就把背景说清楚。他想到什么问什么，你追问一句，他才补充一点。比如他问“可以解除合同吗”，你不知道是什么合同；他说“那个项目”，你不知道是哪个项目。 如果只是简单地把这些话“提取”出来，没有上下文，团队看了也学不到任何东西。 这时候我意识到一个关键：客户要的根本不是“提取问题”，而是 “整合信息” ，把碎片化的对话，拼凑成一份完整的“案情陈述”。 Part 2: 为什么“提取问题”是个伪命题？ 理解了客户的需求后，还是请出老朋友Claude Code，我最初设想的流程非常直接： 读取聊天记录 → 提取问题 → 整理成表格 → 导入飞书。 读取聊天记录用的是上次的方法，但文件比较多（几百个私聊），还好前期已经有目标的客户，只要设计好提取规则，就可以先把需要的文件先整理出来。 然而，第一版做出来，效果惨不忍睹。我很快就撞上了三堵墙。 坑一：提取出的问题，毫无价值 我先提取了 10 个咨询客户的聊天记录，得到了 54 个“问题”。但当我看到结果时，我愣住了： “可以解除合同吗？” “那个项目怎么办？” “律师费多少？” 这些孤立的问题，完全脱离了背景。是什么合同？哪个项目？什么情况？一概不知。这样的“问题库”根本无法共享给团队学习，因为新人看了完全是一头雾水。 坑二：过滤规则，根本没法定 我想，至少应该过滤掉非法律问题吧？比如约时间、打电话、发文件这些日常对话。但实际操作起来，边界极其模糊。 “明天见”要不要过滤？看似是约时间，但可能是在说 开庭时间 。 “收到”要不要过滤？看似是确认，但可能是在确认 一份关键材料 。 过滤规则越想越复杂，我越不敢动手删除任何一条信息。 坑三：分类工作，进退两难 我想，退一步给问题分分类总可以吧？比如合同纠纷、业务咨询、其他。但很快就发现： 人工分类 ：太慢，不具备规模化的可能。 AI 分类 ：在缺乏上下文的情况下，AI 也经常分错。 这时我终于直面了那个 核心矛盾 ：客户咨询是碎片式的，对话散落在几天甚至几周的记录里。简单地“提取问题”，就是在制造信息垃圾。我要的不是“提取”，而是 “整合” 。 Part 3: 关键突破——我用“信息重构”三件套，让 AI 读懂了对话 既然“提取”的路走不通，我必须换个思路。 我意识到，客户的咨询过程其实不是“问了 5 个孤立的问题”，而是“ 围绕一个核心案情，展开了 5 轮问答 ”。 客户的咨询过程通常是这样的： 客户抛出一个模糊的问题（比如“可以解除合同吗？”） 律师追问细节（比如“什么合同？”、“对方是谁？”） 客户补充信息（比如“XX 公司的 xx 合同”） 客户补充回答的过程，就是在 填充咨询背景 。 基于这个思路，我没有让 AI 去“提取”，而是给它定了三条规则，设计了三个逻辑组件，我称之为“信息重构三件套”。 组件一：事实重构 (Fact Reconstruction) 我告诉 cc：不要提取，而是去 重构 。把客户散落在几天对话里的所有信息，整合成一段通顺的 案情陈述 。 这包括： 客户最初的问题 律师所有的追问 客户补充的全部回答 聊天中提到的所有背景信息 cc的任务就像一个侦探，把所有碎片拼起来，形成一个完整的“客户画像”和“案件背景”。 组件二：交互对齐 (Interaction Alignment) 我让 AI 把“客户问+律师答”、“律师问+客户答”的对话 配对 起来。 这样，团队学习时就能清晰地看到： 客户问了什么，他是怎么问的？ 律师是怎么回应的，有没有追问？ 哪些回答是有效的，哪些是无效的？ 组件三：争议焦点抽象 (Conflict Abstraction) 一个客户可能问了很多问题，但 核心矛盾往往只有一个 。我让 AI 用一句话提炼并概括出本次咨询的核心争议点。 通过这三件套，我们实现了从 碎片对话 → 完整案情陈述 的关键一跃。 AI 的核心价值：不是生成，是重构 因为这次需要还原问题原貌，所以 AI 不能凭空创造信息，这三个组件的核心在于—— AI 没有创造任何新信息，只是按照我制定的规则，把零散的信息重新组织了起来。 这是一个根本性的认知转变： ❌ 错误思路 ：把客户的话“提取”出来。 ✅ 正确思路 ：按规则“重构”客户与律师的完整对话。 这个从“怎么提取信息”到“ 怎么重构信息 “的思路转变，远比技术实现本身更重要。 Part 4: 从 2 天到 5 分钟——不止是效率，更是可复用的工作模式 项目完成后，我算了一笔惊人的时间账。 （保护客户隐私，此处就只放厚码截图了） 效率对比：从“天”到“分钟” 人工整理 ：整理 10 个客户的聊天记录，保守估计需要 1 天，全量基本判断老方法起码要3天以上，可能还不止，因为之前在跑这个项目的时候前期已经先把重点咨询过的客户进行了标注，可以通过AI匹配快速定位需要的客户聊天记录 ，而且不可避免地会遗漏信息、记错细节。 cc skill整理 ：最终跑完数据，只花了 3 个小时 。 说实话，这 3 小时里有 2 小时都花在调试上（调整 cc的 Prompt、分类规则、输出格式）。真正跑数据，只用了 1 个小时。 当然，这里还有一个经验要分享，就是不要一上来就全量分析，我一开始先跑通 10 个关键客户的问题提取，效果满意了再全量，既节省 token，又节省来回沟通的使劲按。 平均每个客户的对话，cc 只用 5 分钟就能整理完毕，而且质量远超人工——信息完整、细节准确。 可复用场景：这个模式能用在任何“对话式跟进”中 效率的提升，让我立刻想到了这个模式的可复用性。 场景 1：销售跟进 客户的表达同样是零散的：“预算够吗？”、“能便宜点吗？”、“我还要再想想”，“我的需求是 xxx”。 事实重构 ：整合客户的预算、决策流程、真实顾虑。 交互对齐 ：知道问了什么、怎么答的、哪些承诺有效。 焦点抽象 ：提炼核心顾虑——比如“预算不是问题， 信任才是 ”。 场景 2：学员陪跑 学员的反馈通常是：“不懂”、“不会”、“卡住了”、“在 xx 上，这个就是播不了”。 事实重构 ：整合学员的学习进度、知识薄弱点。 交互对齐 ：知道老师指导了什么、学员吸收了什么。 焦点抽象 ：提炼核心瓶颈——比如“不是技术问题， 是信心问题 ”。 我发现了一个可以被无限复用的核心模式： 碎片式对话 → 【事实重构 + 交互对齐 + 焦点抽象】 → 结构化知识 这个思路可以用到任何需要“对话式跟进”的场景。 Part 5: 总结——从“提取链接”到“重构对话”，不变的是这个核心思路 回顾我最近完成的两个 Skill 项目： 上期项目 ：做“聊天记录 提取 链接“，把微信群聊里的文章链接导入飞书知识库。 这次项目 ：做“私聊问答 整合 “，把一对一的客户咨询整理成完整的案情陈述和关键回复。 表面上看，一个处理链接，一个处理对话，但两次项目的 核心思路是完全一致的 ：把碎片化的信息，转化为可搜索、可复用的结构化知识。 关键差异在于应用的深度： 上次 ：公开群聊的链接提取（重点是 数据清洗，链接爬取方法 ）。 这次 ：私聊问答的内容整合（重点是 信息重构 ）。 而那个“信息重构三件套”其实一直都在： 事实重构 ：整合零散信息 交互对齐 ：配对问答关系 焦点抽象 ：提炼核心价值 上期我用这三件套处理文章链接，这次我用它来处理客户咨询。 工具在变，场景在变，但解决问题的底层逻辑是相通的。 AI 模型会不断更新，技术会飞速进步，但“ 从碎片化信息中提取结构化知识 “这个核心思路，是长期有效的。 上期是这样，本期也是这样。上期链接： Skill 创作手记： 我把微信聊天记录通过skill转化成【可搜索的知识库】 我想，这个关于聊天记录的项目，可能才刚刚开始。 聊天记录，这个最贴近我们生活和工作场景、却最容易被忽视的信息金矿，蕴藏着巨大的价值。我们每天都在产生数据，却没有意识到这些散落在对话里的碎片，其实是未经雕琢的知识资产。 今天我们用‘信息重构’解决了私聊咨询的整合，未来呢？或许可以做多人对话的观点聚合，可以做客户情绪的量化分析，甚至可以还原一个复杂决策背后的完整路径。从‘语料提取’到‘行为洞察’，这扇门一旦打开，能做的事情还有很多。你的聊天记录里，又藏着怎样的宝藏呢？ 
